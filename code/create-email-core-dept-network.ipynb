{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "from datetime import datetime, timedelta\n",
    "import os\n",
    "from graphprocessor import GraphProcessor\n",
    "import numpy as np\n",
    "from IMutil import IMutil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dataset:  \"https://snap.stanford.edu/data/email-Eu-core-temporal.html\" - directed graphs\n",
    "Nodes\t309\n",
    "Temporal Edges\t61046\n",
    "Edges in static graph\t3031\n",
    "Time span\t803 days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_path = 'C:\\\\Priyanka\\\\dynamic-infmax-gnn-lstm\\\\data'\n",
    "dataset = \"\\\\email-Eu-core-temporal-Dept1\"\n",
    "filename= \"\\\\email-Eu-core-temporal-Dept1.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = dir_path + dataset + filename\n",
    "# Assume the dataset is in a CSV file with columns: 'source', 'target', 'time'\n",
    "df = pd.read_csv(file_path,  sep=\" \", header=None, names=[\"SRC\", \"DST\", \"timestamp\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the minimum node number\n",
    "min_node_number = min(df[\"SRC\"].min(), df[\"DST\"].min())\n",
    "min_node_number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "319"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the minimum node number\n",
    "max_node_number = max(df[\"SRC\"].max(), df[\"DST\"].max())\n",
    "max_node_number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "range(0, 320)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the complete set of nodes\n",
    "all_nodes = range(max_node_number + 1)\n",
    "all_nodes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert timestamp to datetime for easy manipulation\n",
    "df['time'] = pd.to_datetime(df['timestamp'], unit='s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a 'month' column to group data by year and month\n",
    "df['month'] = df['time'].dt.to_period('M')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "month\n",
      "1970-01    3115\n",
      "1970-02    2639\n",
      "1970-03    1732\n",
      "1970-04    3360\n",
      "1970-05    3440\n",
      "1970-06    3782\n",
      "1970-07    3574\n",
      "1970-08    5180\n",
      "1970-09    2957\n",
      "1970-10    1955\n",
      "1970-11    3115\n",
      "1970-12    4019\n",
      "1971-01    5032\n",
      "1971-02    1438\n",
      "1971-03    4297\n",
      "1971-04    4819\n",
      "1971-05    4552\n",
      "1971-06    1651\n",
      "1972-03     389\n",
      "Freq: M, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Group edges by month\n",
    "monthly_snapshots = df.groupby('month')\n",
    "\n",
    "# Print the size (number of edges) for each group\n",
    "group_sizes = monthly_snapshots.size()\n",
    "print(group_sizes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph for 1970-01 saved as C:\\Priyanka\\dynamic-infmax-gnn-lstm\\data\\email-Eu-core-temporal-Dept1\\graphs\\snapshot_0.gpickle. Nodes: 320, Edges: 820\n",
      "Graph for 1970-02 saved as C:\\Priyanka\\dynamic-infmax-gnn-lstm\\data\\email-Eu-core-temporal-Dept1\\graphs\\snapshot_1.gpickle. Nodes: 320, Edges: 773\n",
      "Graph for 1970-03 saved as C:\\Priyanka\\dynamic-infmax-gnn-lstm\\data\\email-Eu-core-temporal-Dept1\\graphs\\snapshot_2.gpickle. Nodes: 320, Edges: 595\n",
      "Graph for 1970-04 saved as C:\\Priyanka\\dynamic-infmax-gnn-lstm\\data\\email-Eu-core-temporal-Dept1\\graphs\\snapshot_3.gpickle. Nodes: 320, Edges: 873\n",
      "Graph for 1970-05 saved as C:\\Priyanka\\dynamic-infmax-gnn-lstm\\data\\email-Eu-core-temporal-Dept1\\graphs\\snapshot_4.gpickle. Nodes: 320, Edges: 830\n",
      "Graph for 1970-06 saved as C:\\Priyanka\\dynamic-infmax-gnn-lstm\\data\\email-Eu-core-temporal-Dept1\\graphs\\snapshot_5.gpickle. Nodes: 320, Edges: 831\n",
      "Graph for 1970-07 saved as C:\\Priyanka\\dynamic-infmax-gnn-lstm\\data\\email-Eu-core-temporal-Dept1\\graphs\\snapshot_6.gpickle. Nodes: 320, Edges: 808\n",
      "Graph for 1970-08 saved as C:\\Priyanka\\dynamic-infmax-gnn-lstm\\data\\email-Eu-core-temporal-Dept1\\graphs\\snapshot_7.gpickle. Nodes: 320, Edges: 927\n",
      "Graph for 1970-09 saved as C:\\Priyanka\\dynamic-infmax-gnn-lstm\\data\\email-Eu-core-temporal-Dept1\\graphs\\snapshot_8.gpickle. Nodes: 320, Edges: 716\n",
      "Graph for 1970-10 saved as C:\\Priyanka\\dynamic-infmax-gnn-lstm\\data\\email-Eu-core-temporal-Dept1\\graphs\\snapshot_9.gpickle. Nodes: 320, Edges: 583\n",
      "Graph for 1970-11 saved as C:\\Priyanka\\dynamic-infmax-gnn-lstm\\data\\email-Eu-core-temporal-Dept1\\graphs\\snapshot_10.gpickle. Nodes: 320, Edges: 741\n",
      "Graph for 1970-12 saved as C:\\Priyanka\\dynamic-infmax-gnn-lstm\\data\\email-Eu-core-temporal-Dept1\\graphs\\snapshot_11.gpickle. Nodes: 320, Edges: 909\n",
      "Graph for 1971-01 saved as C:\\Priyanka\\dynamic-infmax-gnn-lstm\\data\\email-Eu-core-temporal-Dept1\\graphs\\snapshot_12.gpickle. Nodes: 320, Edges: 992\n",
      "Graph for 1971-02 saved as C:\\Priyanka\\dynamic-infmax-gnn-lstm\\data\\email-Eu-core-temporal-Dept1\\graphs\\snapshot_13.gpickle. Nodes: 320, Edges: 501\n",
      "Graph for 1971-03 saved as C:\\Priyanka\\dynamic-infmax-gnn-lstm\\data\\email-Eu-core-temporal-Dept1\\graphs\\snapshot_14.gpickle. Nodes: 320, Edges: 1033\n",
      "Graph for 1971-04 saved as C:\\Priyanka\\dynamic-infmax-gnn-lstm\\data\\email-Eu-core-temporal-Dept1\\graphs\\snapshot_15.gpickle. Nodes: 320, Edges: 1029\n",
      "Graph for 1971-05 saved as C:\\Priyanka\\dynamic-infmax-gnn-lstm\\data\\email-Eu-core-temporal-Dept1\\graphs\\snapshot_16.gpickle. Nodes: 320, Edges: 993\n",
      "Graph for 1971-06 saved as C:\\Priyanka\\dynamic-infmax-gnn-lstm\\data\\email-Eu-core-temporal-Dept1\\graphs\\snapshot_17.gpickle. Nodes: 320, Edges: 531\n",
      "Graph for 1972-03 saved as C:\\Priyanka\\dynamic-infmax-gnn-lstm\\data\\email-Eu-core-temporal-Dept1\\graphs\\snapshot_18.gpickle. Nodes: 320, Edges: 248\n"
     ]
    }
   ],
   "source": [
    "# Create output directory if it doesn't exist\n",
    "output_dir = dir_path + dataset + \"\\\\graphs\\\\\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Create and save graphs with sequential names\n",
    "for i, (month, group) in enumerate(monthly_snapshots):\n",
    "    # Create a directed graph for the current month\n",
    "    G = nx.DiGraph()\n",
    "    \n",
    "    # Add all nodes to ensure consistency across snapshots\n",
    "    G.add_nodes_from(all_nodes)\n",
    "    \n",
    "    # Add edges for the current month's snapshot\n",
    "    G.add_edges_from(zip(group['SRC'], group['DST']))\n",
    "\n",
    "    # Save the graph with a sequential name\n",
    "    filename = os.path.join(output_dir, f'snapshot_{i}.gpickle')\n",
    "    nx.write_gpickle(G, filename)\n",
    "\n",
    "    print(f\"Graph for {month} saved as {filename}. Nodes: {G.number_of_nodes()}, Edges: {G.number_of_edges()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Self-loops: 0\n"
     ]
    }
   ],
   "source": [
    "self_loops = [(u, v) for u, v in zip(group['SRC'], group['DST']) if u == v]\n",
    "print(f\"Self-loops: {len(self_loops)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicate edges: 141\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "duplicates = len(group) - len(set(zip(group['SRC'], group['DST'])))\n",
    "print(f\"Number of duplicate edges: {duplicates}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_labels_and_features(G, top_percentile=30, uniinfweight=1.0):\n",
    "    \"\"\"\n",
    "    Add IFC scores, labels, and additional features to each node in the graph.\n",
    "\n",
    "    Parameters:\n",
    "        G (networkx.Graph): Input graph.\n",
    "        top_percentile (float): Top percentile for labeling nodes as `1`.\n",
    "        uniinfweight (float): Weight factor for IFC score calculation.\n",
    "\n",
    "    Returns:\n",
    "        networkx.Graph: Graph with added features and labels.\n",
    "    \"\"\"\n",
    "    # Calculate IFC scores\n",
    "    ifc_scores = IMutil.calculate_ifc_score(G, uniinfweight)\n",
    "\n",
    "    # Sort nodes by IFC score\n",
    "    sorted_nodes = sorted(ifc_scores.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # Determine the cutoff for top x percentile\n",
    "    num_top_nodes = int(len(sorted_nodes) * top_percentile / 100)\n",
    "    top_nodes = {node for node, _ in sorted_nodes[:num_top_nodes]}\n",
    "\n",
    "    # Add features and labels to nodes\n",
    "    for node in G.nodes:\n",
    "        G.nodes[node][\"ifc_score\"] = ifc_scores[node]  # IFC score\n",
    "        G.nodes[node][\"label\"] = 1 if node in top_nodes else 0  # Label\n",
    "        G.nodes[node][\"features\"] = [\n",
    "            G.degree(node),  # Degree\n",
    "            nx.average_neighbor_degree(G)[node],  # Average neighbor degree\n",
    "            G.nodes[node].get(\"existing_feature\", 0),  # Placeholder for other features\n",
    "        ]\n",
    "\n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_and_save_graphs(input_dir, output_dir, top_percentile=30, uniinfweight=1.0):\n",
    "    \"\"\"\n",
    "    Process all graphs in the input directory:\n",
    "    - Calculate IFC scores\n",
    "    - Add labels based on top percentile\n",
    "    - Add features\n",
    "\n",
    "    Parameters:\n",
    "        input_dir (str): Directory containing input graphs.\n",
    "        output_dir (str): Directory to save processed graphs.\n",
    "        top_percentile (float): Top percentile for labeling nodes as `1`.\n",
    "        uniinfweight (float): Weight factor for IFC score calculation.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    for file_name in os.listdir(input_dir):\n",
    "        if file_name.endswith(\".gpickle\"):\n",
    "            # Load graph\n",
    "            graph_path = os.path.join(input_dir, file_name)\n",
    "            G = nx.read_gpickle(graph_path)\n",
    "\n",
    "            # Add features and labels\n",
    "            G = add_labels_and_features(G, top_percentile, uniinfweight)\n",
    "\n",
    "            # Save the modified graph\n",
    "            output_path = os.path.join(output_dir, file_name)\n",
    "            nx.write_gpickle(G, output_path)\n",
    "            print(f\"Processed and saved graph: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "input_dir = \"C:\\\\Priyanka\\\\dynamic-infmax-gnn-lstm\\\\data\\\\email-Eu-core-temporal-Dept1\\\\graphs\\\\\"\n",
    "output_dir = \"C:\\\\Priyanka\\\\dynamic-infmax-gnn-lstm\\\\data\\\\email-Eu-core-temporal-Dept1\\\\graphs-lables\\\\\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed and saved graph: C:\\Priyanka\\dynamic-infmax-gnn-lstm\\data\\email-Eu-core-temporal-Dept1\\graphs-lables\\snapshot_0.gpickle\n",
      "Processed and saved graph: C:\\Priyanka\\dynamic-infmax-gnn-lstm\\data\\email-Eu-core-temporal-Dept1\\graphs-lables\\snapshot_1.gpickle\n",
      "Processed and saved graph: C:\\Priyanka\\dynamic-infmax-gnn-lstm\\data\\email-Eu-core-temporal-Dept1\\graphs-lables\\snapshot_10.gpickle\n",
      "Processed and saved graph: C:\\Priyanka\\dynamic-infmax-gnn-lstm\\data\\email-Eu-core-temporal-Dept1\\graphs-lables\\snapshot_11.gpickle\n",
      "Processed and saved graph: C:\\Priyanka\\dynamic-infmax-gnn-lstm\\data\\email-Eu-core-temporal-Dept1\\graphs-lables\\snapshot_12.gpickle\n",
      "Processed and saved graph: C:\\Priyanka\\dynamic-infmax-gnn-lstm\\data\\email-Eu-core-temporal-Dept1\\graphs-lables\\snapshot_13.gpickle\n",
      "Processed and saved graph: C:\\Priyanka\\dynamic-infmax-gnn-lstm\\data\\email-Eu-core-temporal-Dept1\\graphs-lables\\snapshot_14.gpickle\n",
      "Processed and saved graph: C:\\Priyanka\\dynamic-infmax-gnn-lstm\\data\\email-Eu-core-temporal-Dept1\\graphs-lables\\snapshot_15.gpickle\n",
      "Processed and saved graph: C:\\Priyanka\\dynamic-infmax-gnn-lstm\\data\\email-Eu-core-temporal-Dept1\\graphs-lables\\snapshot_16.gpickle\n",
      "Processed and saved graph: C:\\Priyanka\\dynamic-infmax-gnn-lstm\\data\\email-Eu-core-temporal-Dept1\\graphs-lables\\snapshot_17.gpickle\n",
      "Processed and saved graph: C:\\Priyanka\\dynamic-infmax-gnn-lstm\\data\\email-Eu-core-temporal-Dept1\\graphs-lables\\snapshot_18.gpickle\n",
      "Processed and saved graph: C:\\Priyanka\\dynamic-infmax-gnn-lstm\\data\\email-Eu-core-temporal-Dept1\\graphs-lables\\snapshot_2.gpickle\n",
      "Processed and saved graph: C:\\Priyanka\\dynamic-infmax-gnn-lstm\\data\\email-Eu-core-temporal-Dept1\\graphs-lables\\snapshot_3.gpickle\n",
      "Processed and saved graph: C:\\Priyanka\\dynamic-infmax-gnn-lstm\\data\\email-Eu-core-temporal-Dept1\\graphs-lables\\snapshot_4.gpickle\n",
      "Processed and saved graph: C:\\Priyanka\\dynamic-infmax-gnn-lstm\\data\\email-Eu-core-temporal-Dept1\\graphs-lables\\snapshot_5.gpickle\n",
      "Processed and saved graph: C:\\Priyanka\\dynamic-infmax-gnn-lstm\\data\\email-Eu-core-temporal-Dept1\\graphs-lables\\snapshot_6.gpickle\n",
      "Processed and saved graph: C:\\Priyanka\\dynamic-infmax-gnn-lstm\\data\\email-Eu-core-temporal-Dept1\\graphs-lables\\snapshot_7.gpickle\n",
      "Processed and saved graph: C:\\Priyanka\\dynamic-infmax-gnn-lstm\\data\\email-Eu-core-temporal-Dept1\\graphs-lables\\snapshot_8.gpickle\n",
      "Processed and saved graph: C:\\Priyanka\\dynamic-infmax-gnn-lstm\\data\\email-Eu-core-temporal-Dept1\\graphs-lables\\snapshot_9.gpickle\n"
     ]
    }
   ],
   "source": [
    "# Call the function to add features and labels to graphs and save them\n",
    "process_and_save_graphs(input_dir, output_dir, top_percentile=30, uniinfweight=1.0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "infmax",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
