{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Priyanka\\dynamic-infmax-gnn-lstm\\code\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from collections import Counter \n",
    "import powerlaw\n",
    "import os\n",
    "import random\n",
    "print(os.getcwd())\n",
    "import importlib\n",
    "from utils import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the full path to utils.py\n",
    "path_to_utils = 'c:/Priyanka/dynamic-infmax-gnn-lstm/code/utils.py'\n",
    "\n",
    "# Load the module\n",
    "spec = importlib.util.spec_from_file_location(\"utils\", path_to_utils)\n",
    "utils = importlib.util.module_from_spec(spec)\n",
    "sys.modules[\"utils\"] = utils\n",
    "spec.loader.exec_module(utils)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph: snapshot_0.gpickle Number of nodes & edges : 11492 22002\n",
      "Graph: snapshot_1.gpickle Number of nodes & edges : 11492 21999\n",
      "Graph: snapshot_2.gpickle Number of nodes & edges : 11492 22469\n",
      "Graph: snapshot_3.gpickle Number of nodes & edges : 11492 22747\n",
      "Graph: snapshot_4.gpickle Number of nodes & edges : 11492 22493\n",
      "Graph: snapshot_5.gpickle Number of nodes & edges : 11492 22607\n",
      "Graph: snapshot_6.gpickle Number of nodes & edges : 11492 22677\n",
      "Graph: snapshot_7.gpickle Number of nodes & edges : 11492 22724\n",
      "Graph: snapshot_8.gpickle Number of nodes & edges : 11492 23409\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def graph_details(graph_dir):\n",
    "    # Iterate over the gpickle files in the directory\n",
    "    for file_name in os.listdir(graph_dir):\n",
    "        if file_name.endswith('.gpickle'):\n",
    "            # Construct the full file path\n",
    "            file_path = os.path.join(graph_dir, file_name)\n",
    "            \n",
    "            # Load the graph from the gpickle file\n",
    "            graph = nx.read_gpickle(file_path)\n",
    "            \n",
    "            # Get the number of nodes and edges\n",
    "            num_nodes = graph.number_of_nodes()\n",
    "            num_edges = graph.number_of_edges()\n",
    "            \n",
    "            # Print the number of nodes and edges\n",
    "            print(f\"Graph: {file_name}\", \"Number of nodes & edges :\", num_nodes,  num_edges)\n",
    "    return 1\n",
    "\n",
    "# Define the directory where your graph data files are located\n",
    "\n",
    "data_dir = \"C:\\\\Priyanka\\\\dynamic-infmax-gnn-lstm\\\\data\\\\Oregon-data\\\\graphs\\\\\"\n",
    "graph_details(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get IFC centrality score for each node\n",
    "def get_inflcapapcity(g, uniinfweight):\n",
    "    nodelist = list(g.nodes)\n",
    "    il = np.zeros((len(nodelist), 1))\n",
    "    ig = np.zeros((len(nodelist), 1))\n",
    "\n",
    "    degn = max([nx.degree(g, ind) for ind in g.nodes])\n",
    "\n",
    "    for countnode in range(len(nodelist)):\n",
    "        tempw = 0\n",
    "        for neighbnode in g.neighbors(nodelist[countnode]):\n",
    "            tempw = tempw + uniinfweight * uniinfweight * nx.degree(g, neighbnode)\n",
    "\n",
    "        # local score\n",
    "        il[nodelist[countnode]] = 1 + list(g.degree([nodelist[countnode]], weight='weight'))[0][1] + tempw\n",
    "\n",
    "        # global score\n",
    "        ig[nodelist[countnode]] = nx.core_number(g)[nodelist[countnode]] * (\n",
    "                    1 + (nx.degree(g, nodelist[countnode])) / (degn))\n",
    "\n",
    "    # overall score\n",
    "    ic = np.array([(il[nodelist[countnode]] / np.max(il)) * (ig[nodelist[countnode]] / np.max(ig)) for countnode in\n",
    "                    range(len(nodelist))])\n",
    "\n",
    "    return ic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_influence_capacity_score(ifc_score):\n",
    "    #ifc_score = get_inflcapapcity(graph, 0.5)\n",
    "    threshold = np.percentile(ifc_score, 40)\n",
    "    print(f\"The 90% quartile threshold for IFC scores is: {threshold}\")\n",
    "    top_influencers_indices = [index for index, score in enumerate(ifc_score) if score >= threshold]\n",
    "    #print(top_influencers_indices)\n",
    "    print(\"len\", len(top_influencers_indices))\n",
    "    return top_influencers_indices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_spread_for_all_graphs(data_dir, graphs, k=10, p=0.2, mc=100, uniinfweight=1):\n",
    "    \"\"\"\n",
    "    Computes the spread and IFC scores for a list of graphs.\n",
    "\n",
    "    Parameters:\n",
    "    - graphs (list): List of networkx graph objects.\n",
    "    - k (int): Number of seed nodes to select.\n",
    "    - p (float): Propagation probability.\n",
    "    - mc (int): Number of Monte-Carlo simulations.\n",
    "    - uniinfweight (int): Uniform influence weight for IFC score computation.\n",
    "\n",
    "    Returns:\n",
    "    - results (dict): A dictionary containing results for each graph.\n",
    "    - ifc_scores_dict (dict): A dictionary containing IFC scores for each node in each graph.\n",
    "    \"\"\"\n",
    "    results = {}\n",
    "    ifc_scores_dict = {}\n",
    "\n",
    "    for i, r in enumerate(graphs):\n",
    "        g =nx.read_gpickle(data_dir + graphs[i])\n",
    "        print(graphs[i])\n",
    "        nodes_g, edges_g = g.number_of_nodes(), g.number_of_edges()\n",
    "        print(f\"Computing spread for Graph {i + 1} with {len(g.nodes())} nodes and {len(g.edges())} edges...\")\n",
    "        \n",
    "        # Compute spread with the greedy algorithm\n",
    "        seeds_greedy, spread_greedy, greedy_time= utils.greedy(g, k, p, mc)\n",
    "\n",
    "        # Compute IFC scores\n",
    "        ifc_scores = get_inflcapapcity(g, uniinfweight)\n",
    "        ifc_scores_dict[f\"Graph_{i + 1}\"] = ifc_scores\n",
    "\n",
    "        # Convert IFC scores to a list to find candidate nodes based on top IFC scores\n",
    "        # Assuming we use IFC scores to determine candidate nodes for greedy_mod\n",
    "        # Here we consider top nodes based on IFC scores as candidates\n",
    "        candidate_nodes = top_influence_capacity_score(ifc_scores)\n",
    "\n",
    "        # Compute spread with the greedy_mod algorithm using nodes selected based on IFC scores\n",
    "        seeds_greedy_mod, spread_greedy_mod, ifc_time = utils.greedy_mod(g, k, candidate_nodes , p, mc)\n",
    "\n",
    "        # Store results in a structured dictionary\n",
    "        results[f\"Graph_{i + 1}\"] = {\n",
    "            \"greedy_spread\": spread_greedy,\n",
    "            \"greedy_time\": greedy_time,\n",
    "            \"ifc_time\": ifc_time,\n",
    "            \"greedy_mod_spread\": spread_greedy_mod\n",
    "        }\n",
    "\n",
    "    return results, ifc_scores_dict\n",
    "\n",
    "# Note: Replace `utils.greedy` and `utils.greedy_mod` with just `greedy` and `greedy_mod`\n",
    "# if you are defining these functions in the same script or have imported them correctly.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List the .gpickle files in the data directory\n",
    "graph_paths = [f for f in os.listdir(data_dir) if f.endswith(\".gpickle\")]\n",
    "sorted_graph_paths = sorted(graph_paths, key=lambda x: int(x.split('_')[-1].split('.')[0]))  # Assuming filenames contain index\n",
    "\n",
    "\n",
    "# # Iterate through subsequent graphs\n",
    "# for i in range(0, len(sorted_graph_paths)):\n",
    "#     g1 =nx.read_gpickle(data_dir + sorted_graph_paths[i])\n",
    "#     nodes_g1, edges_g1 = g1.number_of_nodes(), g1.number_of_edges()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "snapshot_0.gpickle\n",
      "Computing spread for Graph 1 with 11492 nodes and 22002 edges...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m ouput \u001b[38;5;241m=\u001b[39m \u001b[43mcompute_spread_for_all_graphs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msorted_graph_paths\u001b[49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muniinfweight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[12], line 26\u001b[0m, in \u001b[0;36mcompute_spread_for_all_graphs\u001b[1;34m(data_dir, graphs, k, p, mc, uniinfweight)\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mComputing spread for Graph \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m with \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(g\u001b[38;5;241m.\u001b[39mnodes())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m nodes and \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(g\u001b[38;5;241m.\u001b[39medges())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m edges...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m# Compute spread with the greedy algorithm\u001b[39;00m\n\u001b[1;32m---> 26\u001b[0m seeds_greedy, spread_greedy, greedy_time\u001b[38;5;241m=\u001b[39m \u001b[43mutils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgreedy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m# Compute IFC scores\u001b[39;00m\n\u001b[0;32m     29\u001b[0m ifc_scores \u001b[38;5;241m=\u001b[39m get_inflcapapcity(g, uniinfweight)\n",
      "File \u001b[1;32mc:/Priyanka/dynamic-infmax-gnn-lstm/code/utils.py:100\u001b[0m, in \u001b[0;36mgreedy\u001b[1;34m(g, k, p, mc)\u001b[0m\n\u001b[0;32m     96\u001b[0m best_spread \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     97\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mset\u001b[39m(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(g\u001b[38;5;241m.\u001b[39mnodes()))) \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mset\u001b[39m(S):\n\u001b[0;32m     98\u001b[0m \n\u001b[0;32m     99\u001b[0m     \u001b[38;5;66;03m# Get the spread\u001b[39;00m\n\u001b[1;32m--> 100\u001b[0m     s \u001b[38;5;241m=\u001b[39m \u001b[43minfluence_spread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mS\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mj\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    102\u001b[0m     \u001b[38;5;66;03m# Update the winning node and spread so far\u001b[39;00m\n\u001b[0;32m    103\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m s \u001b[38;5;241m>\u001b[39m best_spread:\n",
      "File \u001b[1;32mc:/Priyanka/dynamic-infmax-gnn-lstm/code/utils.py:67\u001b[0m, in \u001b[0;36minfluence_spread\u001b[1;34m(g, S, p, mc)\u001b[0m\n\u001b[0;32m     65\u001b[0m     np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mseed(i)\n\u001b[0;32m     66\u001b[0m     outn \u001b[38;5;241m=\u001b[39m [n \u001b[38;5;28;01mfor\u001b[39;00m n \u001b[38;5;129;01min\u001b[39;00m g\u001b[38;5;241m.\u001b[39mneighbors(node)]\n\u001b[1;32m---> 67\u001b[0m     success \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muniform\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutn\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m<\u001b[39m p\n\u001b[0;32m     68\u001b[0m     new_ones \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(np\u001b[38;5;241m.\u001b[39mextract(success, outn))\n\u001b[0;32m     71\u001b[0m new_active \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mset\u001b[39m(new_ones) \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mset\u001b[39m(A))\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "ouput = compute_spread_for_all_graphs(data_dir, sorted_graph_paths , k= 5 , p=0.5, mc=1, uniinfweight=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results, infc_all_graphs = ouput\n",
    "\n",
    "# # Convert the dictionary to a DataFrame\n",
    "# df = pd.DataFrame(results)\n",
    "\n",
    "# # Export the DataFrame to an Excel file\n",
    "# excel_path = 'spread_100_mc.xlsx'  # Specify your path and file name\n",
    "# df.to_excel(excel_path, index=False, engine='openpyxl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "infmax",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
